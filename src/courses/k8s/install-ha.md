---
license: ¬© 2025 Tom Avenel under Û∞µ´  BY-SA 4.0
title: Installation H/A
layout: '@layouts/CoursePartLayout.astro'
---

## üìå Haute Disponibilit√© d'un Cluster Kubernetes

Dans un contexte de **production**, un cluster Kubernetes doit √™tre con√ßu pour **tol√©rer la panne de composants critiques** sans interruption significative du service. La haute disponibilit√© (HA) couvre **le control plane** et la **r√©silience de l'etcd** - le datastore distribu√© qui contient tout l'√©tat du cluster.

### Objectifs

La haute disponibilit√© dans un cluster Kubernetes vise √† :

- **√âliminer le point de d√©faillance unique (SPOF)** de l'API server : ne pas d√©pendre d'un seul n≈ìud pour l'acc√®s au Kubernetes API.
- **Assurer la continuit√© de l'orchestration** : scheduler, contr√¥leurs et autoscaler doivent pouvoir continuer √† fonctionner m√™me si une instance tombe.
- **Maintenir l'√©tat du cluster** : etcd doit rester disponible avec un quorum minimal de membres pour garantir coh√©rence et tol√©rance aux pannes.
- **Servir les workloads applicatifs** m√™me si le control plane est partiellement indisponible.

### Architecture de r√©f√©rence HA

Un cluster Kubernetes HA con√ßu avec `kubeadm` repose sur les composants suivants :

- üõ† Control Plane multiples
- üß† Base d'√©tat etcd distribu√©e
- L'acc√®s aux n≈ìuds du control plane (`api-server`) se fait via un **point d'acc√®s unique hautement disponible** (`ControlPlaneEndpoint`) en utilisant :
  - un **load balancer** TCP (`HAProxy` + `keepalived`)
  - une **virtual IP** (`kube-vip`)
  - un DNS _round-robin_
  - ‚Ä¶

:::link
Voir aussi :

- <https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/>
- <https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/>

:::

## API Server H/A

Chaque _Node_ : `kubelet`, `kube-proxy`, `kube-router`, ‚Ä¶ doivent se lier √† l'`API Server` **dont l'acc√®s doit √™tre H/A**, avec plusieurs possibilit√©s. Dans tous les cas, `kubectl` doit utiliser l'acc√®s H/A publique.

1. **Load Balancer externe** devant les _API Server_

- _Kubelet_ pointe sur ce _load balancer_
- si infra Cloud, souvent g√©r√© par le Cloud Provider
- voir : <https://kifarunix.com/setup-highly-available-kubernetes-cluster-with-haproxy-and-keepalived/>

2. **Load Balancer local** : `Nginx`, `HAProxy`, ‚Ä¶ sur chaque _Node_ pour atteindre les _API Server_

- _Kubelet_ pointe sur `localhost`

3. **round-robin DNS** pour tous les _API Server_ (officiellement non support√© mais aucun impact sur Kubernetes)
4. **Autres** : H/A API endpoint dans un cluster manag√©, virtual IP Cloud, tunnel _Node_ <-> _API Server_ (`k3s`), ‚Ä¶

:::tip
√Ä l'initialisation du cluster (fichier `ClusterConfiguration` ou ligne de commande) :

- `localAPIEndpoint` est l'endpoint local de l'instance de l'api-server sur le noeud courant.
- Dans un cluster comportant plusieurs instances de _control-plane_, le champ `controlPlaneEndpoint`¬†doit contenir l'adresse "publique" du cluster, par exemple _load-balancer_ externe plac√© devant les instances du _control-plane_.
- Dans un cluster sans haute disponibilit√©, `controlPlaneEndpoint` et `localAPIEndpoint` ont la m√™me valeur.
- Voir : [ClusterConfiguration: localAPIEndpoint et controlPlaneEndpoint](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#considerations-about-apiserver-advertise-address-and-controlplaneendpoint)

:::

:::tip
Dans de rares cas (par exemple _k3s_), il est possible de passer d'un cluster mono control-plane √† un cluster H/A √† tout moment.

Mais la plupart du temps (_kubeadm_ par exemple) il n'est pas support√© de changer le `controlPlaneEndpoint`. Une solution est d'utiliser syst√©matiquement un nom DNS dans `controlPlaneEndpoint` qui pourra √™tre :

- Temporairement, l'IP du _control plane_ principal
- Ensuite, la Virtual IP du Load Balancer, ‚Ä¶

:::

:::tip
_kube-vip_ permet de d√©ployer un _load-balancer_ pour des control plane H/A, et pour faire office de service `LoadBalancer` :

- Si cluster install√© par `kubeadm` : n√©essite une _virtual IP_ √† l'installation : la _VIP_ est d√©ploy√©e en _Static Pod_ et stack√©e dans le 1er _control-plane_.
  - les autres _control-plane_ rejoignent la _VIP_ et _kube-vip_ g√®re la r√©plication de la _VIP_.
- Si cluster _k3s_, la _VIP_ n'a pas besoin d'√™tre pr√©sente √† l'initialisation du cluster : celle-ci peut √™tre d√©ploy√©e en `DaemonSet` sur chacun des _Node_.

:::

![Diagramme HA Proxy en frontal de l'api-server](https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2021/09/27/6c1e741a356141a5964e3a64a241ce86.png)

<div class="caption">Diagramme HA Proxy en frontal de l'api-server.</div>

![Diagramme kube-vip stack√© dans le control-plane](https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2021/09/27/6cc2dccc26ac4260bb564a9a4a002670.png)

<div class="caption">Diagramme kube-vip stack√© dans le control-plane.</div>

:::link

- Source des diagrammes et plus d'information : <https://www.sobyte.net/post/2021-09/use-kube-vip-ha-k8s-lb/>
- Voir aussi : <https://kifarunix.com/setup-highly-available-kubernetes-cluster-with-haproxy-and-keepalived/>
- Pour K3s, voir <https://docs.k3s.io/architecture#high-availability-k3s>

:::

## etcd H/A

`etcd` est le composant qui contient toutes les donn√©es du cluster, c'est donc le plus critique et il doit bien entendu √™tre d√©ploy√© en H/A (nombre impair, **5 recommand√©**, 3 support√©).

Voir les documentations officielles : [HA etcd with kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/) et [HA topology](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/) et [configure & upgrade etcd](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/)

:::tip
Il est possible de configurer `etcd` en H/A de 2 mani√®res diff√©rentes (voir la documentation HA topology) :

- _stacked etcd_ : chaque _control plane_ poss√®de un `APIServer` li√© √† un (et un seul) `etcd` install√© dans le _control plane_.
- _external etcd_ : le cluster `etcd` est externe aux _control plane_ : chaque `APIServer` est connect√© au cluster de tous les `etcd`.

:::

![Stacked etcd](@assets/k8s/kubeadm-ha-topology-stacked-etcd.svg)

<div class="caption">etcd en stack dans les control-plane. Source: https://kubernetes.io/images/kubeadm/kubeadm-ha-topology-stacked-etcd.svg</div>

![External etcd](@assets/k8s/kubeadm-ha-topology-external-etcd.svg)
<div class="caption">etcd externes. Source: https://kubernetes.io/images/kubeadm/kubeadm-ha-topology-external-etcd.svg</div>

:::link
Source des diagrammes et plus d'information : <https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/>
:::

## Proc√©dure d'installation H/A

On effectue donc en principe l'odre de d√©ploiement suivant :

- Cr√©ation d'un 1er noeud _control plane_ (aussi appel√© _master_) :
  - d√©ploiement `etcd` (ou BDD).
  - d√©ploiement `api-server` utilisant l'`etcd`.
    - cr√©ation de la configuration du `kubelet`, d√©ploiement et enregistrement aupr√®s de l'`api-server`.
    - d√©ploiement `control-manager` et `scheduler` et enregistrement aupr√®s de l'`api-server`
- Cr√©ation des autres _control plane_ :
  - d√©ploiement des composants (similaire au 1er noeud) mais enregistrement des composants HA aupr√®s du 1er _control plane_, notamment `api-server` et `etcd`.
  - choisir une solution de load balancing adapt√©e : `kube-vip`, `MetalLB`, ‚Ä¶
  - mettre en place une strat√©gie de sauvegarde r√©guli√®re de la base etcd et pr√©voir des m√©canismes de restauration en cas de d√©faillance.
- Cr√©ation des workers :
  - cr√©ation de la configuration du `kubelet`, d√©ploiement et enregistrement aupr√®s de l'`api-server`.

```sh
# pr√©requis : Bastion =>
# - Soit : Installation d'un HAProxy entre les OS des Control Plane
# - Soit : D√©ploiement d'un kube-vip en utilisant un manifest de Pod statique pendant l'init
# - Soit : D√©f√©rer le H/A apr√®s l'installation du 1er control plane (k3s)

# Init du 1e master
kubeadm init --control-plane-endpoint "<IP_bastion>:6443" --pod-network-cidr=100.0.0.0/16 --upload-certs
# Join des autres control-plane
kubeadm join "<IP_bastion>:6443" --token "<TOKEN>" --discovery-token-ca-cert-hash "sha256:<HASH>" --control-plane --certificate-key "<HASH_CERT>"
# Join des workers
kubeadm join "<IP_bastion>:6443" --token "<TOKEN>" --discovery-token-ca-cert-hash "sha256:<HASH>"
# calico, ‚Ä¶
```
