---
license: Â© 2025 Tom Avenel under ó°µ«  BY-SA 4.0
title: ğŸ§ª DÃ©bug dans Kubernetes
layout: '@layouts/CoursePartLayout.astro'
tags:
- docker
- kubernetes
- devops
- debug
---

## ğŸ§­ StratÃ©gie de DÃ©bug en Kubernetes ğŸ”ğŸ”§

- Approche du **bas vers le haut** :
  - Commencer **au niveau du pod**
  - Puis valider chaque niveau **jusqu'Ã  l'utilisateur final**.
  - Permet de **remonter progressivement** vers la source du problÃ¨me.

---

### ğŸ§± 1. **Infrastructure applicative** : Pod â†’ ReplicaSet â†’ Deployment (ou autre)

#### Pod

```sh
kubectl logs pod
kubectl describe pod
kubectl exec -it pod -- /bin/sh
kubectl debug -it pod --image=paulbouwer/hello-kubernetes:1.8
```

:::link
Voir [la cheatsheet](/k8s/cheatsheet#debug)
:::

#### ReplicaSet

```sh
kubectl describe rs
kubectl get rs -o wide
```

#### Deployment / CronJob / StatefulSet

```sh
kubectl describe deployment my-app
kubectl get deploy/statefulset/cronjob
```

---

### ğŸŒ 2. **Exposition rÃ©seau** : Pod â†’ Service â†’ Ingress

#### Pod

```sh
curl localhost:port
# VÃ©rifier les ports exposÃ©s
```

#### Service

```sh
kubectl get svc
kubectl get endpoints
kubectl describe svc my-service
curl my-service:port # depuis un autre pod
```

#### Ingress

```sh
kubectl describe ingress
kubectl logs ingress-controller

# Tester le nom de domaine + vÃ©rification DNS
```

---

### ğŸ§° 3. **Outils** utiles Ã  tous les niveaux

```sh
kubectl get all
kubectl describe
kubectl logs
kubectl exec
kubectl get events --sort-by=.metadata.creationTimestamp`

# Depuis un Pod
nslookupcurl
ping
```

---

## ğŸ§­ DÃ©terminer la cause de l'Ã©chec d'un Pod ğŸ’¥

---

1. ğŸ” **Inspecter l'Ã©tat du pod**

```sh
kubectl get pod my-pod
```

:::tip
Rechercher les Ã©tats : `CrashLoopBackOff`, `Error`, `Pending`.
:::

---

2. ğŸ“œ **Examiner les Ã©vÃ©nements du pod**

```sh
kubectl describe pod my-pod
# VÃ©rifier les erreurs d'ordonnancement ou d'image.
```

---

3. ğŸ“¦ **Consulter les logs**

```sh
kubectl logs my-pod

# Avec plusieurs conteneurs :
kubectl logs my-pod -c my-container
```

---

4. ğŸš **RedÃ©marrer un pod en mode interactif**

```sh
# Ouvrir un terminal sur le Pod :
kubectl run -it --rm debug --image=busybox -- sh
```

---

5. âš ï¸ **VÃ©rifier les probes**
   - Readiness / Liveness mal configurÃ©es ?

---

6. ğŸ§° **Utiliser les outils CLI**
   - `kubectl exec`, `kubectl cp`, `kubectl port-forward` pour un diagnostic plus poussÃ©.

---

:::link

- Voir la cheatsheet pour les commandes de diagnostic.
- Voir les liens de cours pour des exemples d'images de conteneurs utiles pour le debug.

:::

---

## ğŸ³ Pods en erreur : problÃ¨mes courants âš ï¸

---

### ğŸ³ Erreur `ImagePullBackOff` ğŸ“¦ğŸš«

#### ğŸ›‘ Diagnostic

```sh
kubectl get pods
# STATUS: ImagePullBackOff
```

```sh
kubectl describe pod my-pod
# VÃ©rifier l'erreur exacte dans les events
```

---

#### ğŸ” Causes frÃ©quentes

- âŒ **Nom d'image invalide**
- ğŸ”– **Tag inexistant ou mal orthographiÃ©**
- ğŸ” **ProblÃ¨me d'accÃ¨s Ã  une registry privÃ©e**
  - Le pod n'a pas accÃ¨s Ã  la registry (DockerHub, GitHub Container Registry, etc.)
  - Solution : CrÃ©er un `Secret` de type `docker-registry` :

    ```sh
    kubectl create secret docker-registry regcred \
      --docker-server=DOCKER_SERVER \
      --docker-username=DOCKER_USER \
      --docker-password=DOCKER_PASS \
      --docker-email=EMAIL
    ```

  - L'utiliser dans le `spec` :

    ```yaml
    imagePullSecrets:
    - name: regcred
    ```

  - Tester le **pull manuel** :

    ```sh
    docker pull myregistry.com/myimage:tag
    ```

---

### ğŸ” Erreur `CrashLoopBackOff` ğŸ”„ğŸ’¥

#### ğŸ›‘ Diagnostic

```sh
kubectl get pods
# STATUS: CrashLoopBackOff
```

```sh
kubectl describe pod my-pod
kubectl logs my-pod --previous
```

- Utiliser `--previous` pour voir les logs **du dernier conteneur plantÃ©**

---

#### ğŸ” Causes frÃ©quentes

- ğŸ’¥ L'application dans le conteneur **crashe au dÃ©marrage**
- ğŸ”‚ Kubernetes tente de la redÃ©marrerâ€¦ encore et encore
- â±ï¸ Les probes `readiness` ou `liveness` Ã©chouent systÃ©matiquement
- ğŸš La commande `command` ou `args` du pod est incorrecte

---

#### âœ… RÃ©solution

- VÃ©rifier les variables d'environnement attendues
- Tester l'image manuellement en local :

  ```sh
  docker run -it myimage:tag /bin/sh
  ```

---

### ğŸ’£ Erreur `OOMKilled` (Out Of Memory) ğŸ§ ğŸ”¥

#### ğŸ›‘ SymptÃ´me

```sh
kubectl get pod my-pod
kubectl describe pod my-pod
# State: Terminated, Reason: OOMKilled
```

---

#### ğŸ” Causes

- ğŸš« Le conteneur a dÃ©passÃ© la **limite de mÃ©moire dÃ©finie**
- Kubernetes l'a **tuÃ© automatiquement**

#### ğŸ’¡ Exemple de spec mÃ©moire

```yaml
resources:
  limits:
    memory: "128Mi"
  requests:
    memory: "64Mi"
```

---

#### âœ… Solutions

- ğŸ” Augmenter la mÃ©moire disponible si nÃ©cessaire
- ğŸ§ª Optimiser la consommation mÃ©moire de l'application
- ğŸ“Š Mettre en place du **monitoring mÃ©moire** (Prometheus, cAdvisor, etc.)

---

### ğŸš« Erreur `RunContainerError` ğŸšğŸ³

#### ğŸ›‘ Diagnostic

```sh
kubectl get pods
# STATUS: RunContainerError
```

```sh
kubectl describe pod my-pod
# Ã‰vÃ©nement : `Failed to start container`
```

- Le **conteneur** n'a pas pu Ãªtre crÃ©Ã©
  - ProblÃ¨me de configuration du conteneur
  - Inutile de regarde les logsâ€¦
    - â€¦L'application n'a pas encore dÃ©marrÃ© !

---

#### ğŸ” Causes frÃ©quentes

- â— **Erreur dans la commande de dÃ©marrage**
  - Commande ou binaire inexistant dans l'image :

    ```yaml
    command: ["/start.sh"]  # mais start.sh n'existe pas ?
    ```

- ğŸš Shell absent ou mauvaise syntaxe :

  ```yaml
  command: ["bash", "-c", "my-command"]  # mais bash n'est pas dans l'image ?
  ```

- ğŸ”§ EntrÃ©e `args:` mal formÃ©e ou mal utilisÃ©e avec `command:`
- ğŸ” **Volumes montÃ©s incorrectement** ou fichiers attendus absents
- âš™ï¸ Permissions insuffisantes (exÃ©cuter un script non-exÃ©cutable)

---

#### âœ… RÃ©solution

- ğŸ” Tester localement avec Docker :

  ```sh
  docker run -it myimage /bin/sh
  ```

- ğŸ”§ VÃ©rifier le binaire ou script dans l'image :

  ```sh
  docker run myimage ls /start.sh
  ```

- âœ… Rendre les scripts exÃ©cutables (`chmod +x`)
- ğŸ§ª PrivilÃ©gier des images de debug (`alpine`, `busybox`, etc.) pour tester

---

### â³ Pod bloquÃ© en Ã©tat `Pending` ğŸ’¤ğŸ“¦

#### ğŸ›‘ Diagnostic

```sh
kubectl get pods
# STATUS: Pending
```

```sh
kubectl describe pod my-pod
```

- Chercher la cause prÃ©cise dans les **Events** :

  - `0/3 nodes are available: 3 Insufficient memory`
  - `no matching tolerations`
  - `failed to bind volumes`

---

#### ğŸ” Causes frÃ©quentes

- ğŸ§  **Pas assez de ressources disponibles** (CPU / RAM) sur les noeuds du cluster
- ğŸš« **Tolerations / nodeSelector / affinity** trop restrictifs (aucun noeud Ã©ligible)
  - âš ï¸ cause la plus probable !
- ğŸ“¦ **PVC non liÃ©** (volume non encore attachÃ© ou indisponible)
- ğŸŒ©ï¸ ProblÃ¨mes avec le **CNI** (plugin rÃ©seau non fonctionnel)
- ğŸ·ï¸ **Taints sans tolerations** : le pod ne peut pas s'installer sur un noeud

---

#### âœ… Solutions

- ğŸ“‰ **RÃ©duire les ressources demandÃ©es** :

  ```yaml
  resources:
    requests:
      memory: "1Gi"
      cpu: "1"
  ```

- ğŸ”§ Adapter `nodeSelector`, `affinity`, ou `tolerations` :

  ```yaml
  nodeSelector:
    disktype: ssd
  ```

- ğŸ§° VÃ©rifier les volumes :

  ```sh
  kubectl get pvc
  ```

- ğŸŒ VÃ©rifier le plugin rÃ©seau (CNI) :

  ```sh
  kubectl get pods -n kube-system
  ```

---

### ğŸŸ¢ Pod `Running` mais `NotReady` ğŸƒâŒ

#### ğŸ›‘ Diagnostic

```sh
kubectl get pods
# STATUS: Running
# READY: 0/1
```

```sh
kubectl describe pod my-pod
```

- Chercher dans les **Events** :
  - `Unhealthy` : `Readiness probe failed: connection refused`
  - `HTTP probe failed with statuscode: 500`

```sh
kubectl get endpoints my-service
```

- VÃ©rifier si le DNS du service attendu par le pod est bien **rÃ©solu et joignable**

---

#### ğŸ” Causes frÃ©quentes

- ğŸ§ª **Probes d'Ã©tat (`readinessProbe`) qui Ã©chouent**
- â³ **Service dÃ©pendant non encore accessible** (ex: base de donnÃ©es)
- âš ï¸ **Configuration manquante ou incorrecte** (ex : variables d'environnement non dÃ©finies)
- ğŸ” **ProblÃ¨mes d'accÃ¨s rÃ©seau ou DNS**
- ğŸ“¦ Attente de **volume montÃ©** ou de service externe

---

#### âœ… Bonnes pratiques

- âœ”ï¸ Testez les probes en local :

  ```yaml
  readinessProbe:
    httpGet:
      path: /health
      port: 8080
  ```

- ğŸ§ª Lancez un shell dans le pod pour tester vous-mÃªme :

  ```sh
  kubectl exec -it my-pod -- curl http://localhost:8080/health
  ```

- ğŸ“Š Activez les logs d'application pour voir si un service manque ou crashe au dÃ©marrage
- ğŸŒ DÃ©sactivez temporairement la `readinessProbe` pour identifier si elle est responsable

---

## ğŸ™ ProblÃ¨mes rÃ©seau

- ğŸš¨ Cause frÃ©quente de dysfonctionnement dans un cluster Kubernetes :
  - ğŸ”Œ Connexions entre Pods qui Ã©chouent.
  - ğŸš« Services qui ne rÃ©pondent pas.
  - â“ RÃ©solution DNS qui Ã©choue.

---

### ğŸ§ª VÃ©rifier la connectivitÃ© entre Pods ğŸ”

- ğŸ› ï¸ Utiliser des outils comme `curl`, `wget`, `telnet` ou `netcat` (`nc`).
- âœ… Exemple :

  ```sh
  kubectl exec -it pod-a -- curl http://pod-b:8080
  ```

- ğŸ” VÃ©rifier l'IP du pod cible :

  ```sh
  kubectl get pod pod-b -o wide
  ```

---

### ğŸ§ª VÃ©rifier la connectivitÃ© entre Pods et Services ğŸŒ‰

- ğŸ“‹ Assurez-vous que le Service cible existe :

  ```sh
  kubectl get svc
  ```

- ğŸŒ Tester l'accÃ¨s via le nom DNS du service :

  ```sh
  kubectl exec -it pod-a -- curl http://my-service.namespace.svc.cluster.local
  ```

- ğŸ§¬ VÃ©rifiez les endpoints associÃ©s :

  ```sh
  kubectl get endpoints my-service
  ```

---

### ğŸ§ª VÃ©rifier la rÃ©solution DNS ğŸ”ğŸ“¡

- ğŸ§° Tester le DNS avec `nslookup` ou `dig` :

  ```sh
  kubectl exec -it pod-a -- nslookup my-service
  ```

- ğŸ“¡ Le DNS est gÃ©rÃ© par `CoreDNS`, vÃ©rifiez qu'il est actif :

  ```sh
  kubectl get pods -n kube-system -l k8s-app=kube-dns
  ```

---

### ğŸ› ï¸ DÃ©bug avec un pod utilitaire ğŸ§°

- ğŸš€ DÃ©ployer un pod utilitaire avec des outils rÃ©seau :

  ```sh
  kubectl run nettools --image=busybox:1.28 --rm -it --restart=Never -- sh
  ```

- ğŸ”§ Utiliser `wget`, `nslookup`, `telnet`, â€¦ pour diagnostiquer.

---

### ğŸ” VÃ©rifier les NetworkPolicies ğŸš«ğŸ“¡

- ğŸ›¡ï¸ Des politiques rÃ©seau peuvent bloquer la communication.
- ğŸ” VÃ©rifier s'il existe des `NetworkPolicy` :

  ```sh
  kubectl get networkpolicy
  ```

- ğŸ“‘ Inspectez leur contenu :

  ```sh
  kubectl describe networkpolicy my-policy
  ```

---

### ğŸ¯ Pas de routage rÃ©seau

- Service mal configurÃ©
- ğŸŒ VÃ©rifier les ports exposÃ©s : `port` / `targetPort` / `containerPort` ğŸ¯

```yaml
apiVersion: v1
kind: Service
spec:
  ports:
    - port: 80         # Port du service
      targetPort: 8080 # Port du conteneur
```

```yaml
containerPort: 8080  # âœ… Doit correspondre au targetPort du Service
```

- ğŸ§ª VÃ©rification :

```sh
kubectl describe svc my-service
kubectl describe pod my-pod
```

---

### ğŸ¯ Le Service ou le Deployment ne cible aucun Pod

- âš™ï¸ VÃ©rifier les correspondances `label` / `selector` ğŸ”—

#### ğŸ” Exemple pour un Service

  ```yaml
  selector:
    app: web
  ```

- âœ… VÃ©rifier que les Pods ont les bons labels :

  ```sh
  kubectl get pods --show-labels
  ```

#### ğŸ§ª Exemple pour un Deployment

```yaml
selector:
  matchLabels:
    app: myapp
template:
  metadata:
    labels:
      app: myapp  # ğŸ”¥ doit correspondre exactement
```

---

### ğŸ›£ï¸ DÃ©boguer un Ingress Controller ğŸŒğŸ§ª

#### ğŸ›‘ SymptÃ´me

- L'application est inaccessible via l'URL publique (erreur 404, 502, connexion refusÃ©e).
- Le nom de domaine pointe bien vers l'IP du cluster, mais la route ne fonctionne pas.

---

#### ğŸ§ª Ã‰tapes de diagnostic

âœ… **1. VÃ©rifier que l'Ingress Controller est bien installÃ© :**

```sh
kubectl get pods -n traefik
```

- Exemple de pod : `traefik-ingress-controller-7d6f4c5d6-abcde`
- VÃ©rifier qu'il est **Running** et **Ready**

âœ… **2. VÃ©rifier l'Ingress lui-mÃªme :**

```sh
kubectl get ingress
kubectl describe ingress my-ingress
```

- Voir les rÃ¨gles (`rules:`), chemins (`paths:`), et services cibles.
- âš ï¸ Chercher les erreurs dans les events (ex : "no endpoints").
- VÃ©rifier la cohÃ©rence de : `service.name` et `service.port.number` :

```yaml
rules:
- http:
    paths:
    - path: /api
      pathType: Prefix
      backend:
        service:
          name: my-service  # âœ… nom du Service
          port:
            number: 80      # âœ… port exposÃ© par le Service
```

âœ… **3. VÃ©rifier le Service backend :**

- Le service mentionnÃ© dans l'Ingress doit exister et Ãªtre exposÃ© sur le bon port.
- VÃ©rifier la cohÃ©rence de : `service.name` et `service.port.number` :

```sh
kubectl get svc
kubectl get endpoints my-service
```

âœ… **4. VÃ©rifier la rÃ©solution DNS interne :**

```sh
kubectl exec -it some-pod -- nslookup my-service
```

âœ… **5. Tester l'accÃ¨s depuis un pod dans le cluster :**

```sh
kubectl exec -it some-pod -- curl http://my-service:port
```

---

#### ğŸ” Autres points Ã  contrÃ´ler

- ğŸ“¦ **Annotations** spÃ©cifiques au type d'Ingress Controller (non gÃ©nÃ©riques), ex :

  ```yaml
  kubernetes.io/ingress.class: nginx
  nginx.ingress.kubernetes.io/rewrite-target: /
  ```

- ğŸ”§ **TLS actif ?** Si oui, vÃ©rifier le certificat :

  ```sh
  kubectl get secret tls-secret
  ```

- ğŸªµ **Logs du contrÃ´leur :**
  - Erreurs de routing ou d'accÃ¨s backend (`upstream unavailable`, `host not found`, etc.)

```sh
kubectl logs -n traefik deploy/traefik-ingress-controller
```

---
