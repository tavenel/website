---
title: D√©couverte et prise en main de MCP avec Docker
date: 2025 / 2026
---

## üéØ Objectifs p√©dagogiques

- D√©finir le r√¥le du **Model Context Protocol (MCP)**
- Comprendre l'int√©r√™t de **Docker** pour encapsuler un serveur MCP
- D√©ployer un serveur MCP minimal
- Exposer un **tool MCP simple**
- Interagir avec le serveur MCP via un client LLM
- Identifier les cas d'usage possibles de MCP

## üìå Contexte

Les mod√®les de langage (LLM) sont puissants, mais **ne peuvent pas acc√©der directement** aux syst√®mes, fichiers ou API internes d'une organisation.

Le **Model Context Protocol (MCP)** permet de r√©soudre ce probl√®me en standardisant la fa√ßon dont un LLM :

- d√©couvre des outils,
- consomme des ressources,
- interagit avec des services externes.

Dans ce TP, vous allez **conteneuriser un serveur MCP** et lui exposer progressivement des capacit√©s simples.

## üß± Architecture cible

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client LLM      ‚îÇ
‚îÇ (Claude / CLI)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ MCP
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Serveur MCP     ‚îÇ  ‚Üê Docker
‚îÇ (Python / Node) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ Outils & Contextes   ‚îÇ
 ‚îÇ - Fichiers           ‚îÇ
 ‚îÇ - API REST           ‚îÇ
 ‚îÇ - Commandes syst√®me  ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üß™ Comprendre MCP

> MCP est un protocole standard permettant √† un LLM de d√©couvrir et d'appeler des outils externes de mani√®re structur√©e et s√©curis√©e.

En utilisant un LLM, r√©pondre aux questions suivantes :

- Quel est le r√¥le d'un **MCP Server** ?
- Quelle diff√©rence entre un **tool** et une **resource** ?
- Pourquoi MCP est-il ind√©pendant du mod√®le de langage ?

:::correction
**1. R√¥le d'un MCP Server**
Un serveur MCP est un **interm√©diaire standardis√©** entre un mod√®le de langage et des capacit√©s externes (outils, fichiers, API). Il expose explicitement ce que le LLM a le droit de faire, sous une forme structur√©e et contr√¥l√©e.

**2. Diff√©rence entre tool et resource** :

- **Tool** : action ex√©cutable (fonction, appel API, calcul, requ√™te)
- **Resource** : donn√©e statique ou semi-statique (fichier, documentation, configuration)

**3. Pourquoi MCP est ind√©pendant du LLM**
Le protocole est agnostique du mod√®le : n'importe quel LLM compatible MCP peut consommer les m√™mes outils sans modification c√¥t√© serveur.
:::

## üê≥ Mise en place du projet Docker

:::exo

1. Cr√©er l'arborescence suivante :

```
mcp-docker-tp/
‚îú‚îÄ server/
‚îÇ  ‚îú‚îÄ app.py
‚îÇ  ‚îú‚îÄ requirements.txt
‚îÇ  ‚îî‚îÄ Dockerfile
‚îî‚îÄ docker-compose.yml
```

2. Installer une impl√©mentation MCP en Python
3. Compl√©ter le `Dockerfile` :
   - image de base Python
   - installation des d√©pendances
   - lancement du serveur MCP
4. Construire et lancer le conteneur

   ```bash
   docker compose up --build
   ```

5. V√©rifier les logs

:::

:::correction

### `requirements.txt`

```txt
# requirements.txt
mcp
psutil
```

### `app.py`

```py
# app.py
exit
```

### `Dockerfile`

```dockerfile
# Dockerfile

FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY app.py .

ENV PYTHONUNBUFFERED=1

CMD ["python", "app.py"]
```

### `compose.yml`

```yaml
# compose.yml
services:
  mcp-server:
    build: ./server
    container_name: mcp-server
    volumes:
      - ./data:/data
    ports:
      - "3333:3333"
```

### Lancement

```bash
docker compose up --build
```

:::

## üîß Premier serveur MCP minimal

Objectif : Cr√©er un serveur MCP **fonctionnel mais minimal**.

:::exo

1. Impl√©menter un serveur MCP exposant un _tool_ `hello`
2. Le tool retourne :
   - un message statique
   - le nom du conteneur
3. Tester l'appel depuis le client LLM : `StreamableHTTP`, `Connection Type: via proxy`, `URL:` : <http://localhost:8000/mcp> :

  ```sh
  DANGEROUSLY_OMIT_AUTH=true npx -y @modelcontextprotocol/inspector
  ```

:::

### Exemple attendu

```json
{
  "message": "Hello from MCP",
  "container": "mcp-server"
}
```

:::correction

### `app.py`

[TODO]

```python
# app.py
from mcp.server import Server
from mcp.types import Tool, TextContent
import socket

server = Server("demo-mcp-server")

@server.tool(
    name="hello",
    description="Retourne un message de bienvenue depuis le serveur MCP"
)
def hello():
    return [
        TextContent(
            type="text",
            text=f"Hello from MCP running in container {socket.gethostname()}"
        )
    ]

if __name__ == "__main__":
    server.run(port=3333)
```

:::

## üñ•Ô∏è Exposer un tool syst√®me

Objectif : Permettre au LLM d'interroger des informations syst√®me simples.

:::exo

1. Ajouter un tool MCP `system_info`
2. Le tool retourne :
   - nom de l'OS
   - version Python
   - uptime du conteneur
3. V√©rifier que :
   - aucune commande arbitraire n'est possible
   - les sorties sont structur√©es (JSON)

:::

:::tip
Pourquoi est-il dangereux d'exposer directement une commande shell au LLM ?
:::

:::correction

### R√©ponse √† la question guid√©e

**Pourquoi ne pas exposer un shell directement ?**
Parce qu'un LLM pourrait :

- ex√©cuter des commandes destructrices
- exfiltrer des donn√©es
- compromettre l'h√¥te ou le cluster

MCP impose une **surface d'attaque minimale**.
:::

## üìÑ Exposer une resource MCP

Objectif : Permettre au LLM de lire un fichier local.

:::exo

1. Cr√©er un fichier `data/info.txt`
2. Monter ce fichier comme volume Docker
3. Exposer une **resource MCP** : `info_file`
4. Permettre au LLM de :
   - lire le contenu
   - le r√©sumer

## üîê S√©curit√© et isolation

:::exo
R√©pondre aux questions suivantes :

1. Quel est l'int√©r√™t de Docker dans ce TP ?
2. Que se passerait-il si MCP tournait directement sur l'h√¥te ?
3. Quels types de tools ne devraient jamais √™tre expos√©s ?
4. Comment limiter les risques (permissions, sandbox, RBAC) ?

:::

:::correction
**1. R√¥le de Docker**

- Isolation du runtime
- Contr√¥le des volumes
- Limitation de l'impact en cas de compromission

**2. MCP sans Docker**

- Acc√®s direct au syst√®me h√¥te
- Risque majeur d'escalade de privil√®ges

**3. Tools √† ne jamais exposer**

- Shell g√©n√©rique
- Acc√®s r√©seau arbitraire
- Acc√®s aux secrets bruts

**4. Bonnes pratiques**

- Principe du moindre privil√®ge
- Tools tr√®s sp√©cifiques
- Validation stricte des entr√©es
- Logs et audit

:::

## üöÄ Pour aller plus loin (facultatif)

- Ajouter un second service via `docker-compose`
- Ajouter une authentification simple
- Exposer une API REST externe
- D√©ployer le serveur MCP sur Kubernetes

[TODO]
===

## üñ•Ô∏è √âtape 4 ‚Äì Tool syst√®me `system_info`

### Impl√©mentation

```python
import platform
import time
import psutil
from datetime import timedelta

@server.tool(
    name="system_info",
    description="Retourne des informations syst√®me basiques du conteneur"
)
def system_info():
    uptime_seconds = time.time() - psutil.boot_time()

    return [
        TextContent(
            type="text",
            text=f"""
OS: {platform.system()} {platform.release()}
Python: {platform.python_version()}
Uptime: {timedelta(seconds=int(uptime_seconds))}
"""
        )
    ]
```

---

## üìÑ √âtape 5 ‚Äì Resource MCP (fichier local)

:::correction

### Fichier local

`data/info.txt`

```txt
Ce projet d√©montre l'utilisation de MCP avec Docker.
Il permet √† un LLM d'interagir avec des outils et des fichiers locaux
de mani√®re s√©curis√©e et contr√¥l√©e.
```

### Ajout de la resource

```python
from mcp.types import Resource

@server.resource(
    name="info_file",
    description="Fichier d'information du projet"
)
def info_file():
    with open("/data/info.txt", "r") as f:
        content = f.read()

    return [
        TextContent(
            type="text",
            text=content
        )
    ]
```

:::

### R√©sultat attendu

Le LLM peut :

- lire le fichier
- le r√©sumer
- r√©pondre √† des questions bas√©es sur son contenu
