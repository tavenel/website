---
title: Hors piste
created: 2025-09-26
checked: 2025-09-26
---

## Cerveau, Apprentissage, Métacognition

### Notions d'apprentissage

- **Cessité attentionnelle** : lors d'un focus fort sur une tâche, peu d'attention au reste
  - Voir l'expérience du gorille dans ce podcast : <https://www.radiofrance.fr/franceculture/podcasts/votre-cerveau/l-attention-4589382>
  - Voir l'expérience de ce podcast : <https://www.radiofrance.fr/franceculture/podcasts/votre-cerveau/votre-cerveau-cree-en-se-liberant-du-jugement-5137741>
  - Vidéo Youtube : [selective attention test](https://www.youtube.com/watch?v=IGQmdoK_ZfY)
- **Inhibition** : capacité du cortex préfrontal à sortir des routines et automatismes
  - Voir l'expérience de l'effet Stroop : <https://biais-psychologiques.com/biais/effet-stroop/> et podcast : <https://www.radiofrance.fr/franceculture/podcasts/votre-cerveau/l-inhibition-et-la-flexibilite-3735919>
- La **récompense** permet d'appliquer une **motivation extrinsèque** (de l'extérieur) à l'apprentissage à court terme mais **au détriment de la motivation intrinsèque** (interne à l'apprenant) sur le long terme (à minimiser donc).
  - Pour promouvoir la **motivation intrinsèque** : mettre le focus sur l'apprentissage de nouvelles compétences & l'interaction entre apprenants
  - La **motivation intrinsèque** nécessite de ne **pas travailler directement pour l'évaluation** (qui peut quand même venir après)
  - Voir les podcasts : <https://www.radiofrance.fr/franceculture/podcasts/votre-cerveau/la-motivation-et-l-esprit-de-changement-1962894> et <https://www.radiofrance.fr/franceculture/podcasts/votre-cerveau/votre-cerveau-cree-en-se-liberant-du-jugement-5137741>
- L'utilisation des **émotions** permet un engagement fort :
  - Émotion positive : succès de la réalisation, reconnaissance de la réussite, plaisir et bien-être dans le groupe, …
  - Émotion négative : situation future néfaste pouvant être évitée par la réalisation de la tâche ou de l'apprentissage, peur de passer à côté d'une opportunité (bien connu en marketing), …
- **Mémorisation** :
  - Tout le monde apprend à peu près pareil (pas de "visuels", "auditifs", …). Le meilleur apprentissage est croisé (visuel + auditif + …). Voir : [L'impact de la stimulation multi-sensorielle sur la mémorisation à long terme (UGA ESPE Grenoble)](https://dumas.ccsd.cnrs.fr/dumas-01280883)
  - Éviter le _"par coeur"_ peu efficace. Privilégier un **traitement profond** (basé sur le **sens** des informations)
  - Travailler par associations. Excellent podcast (10') : <https://www.radiofrance.fr/franceculture/podcasts/votre-cerveau/comment-fonctionne-votre-memoire-1-6-non-apprendre-par-coeur-n-est-pas-tres-efficace-2431233>
  - S'impliquer **personnellement** et utiliser des références à **soi-même**
  - Apprentissage basé sur l'**action** : il est beaucoup plus simple de se rappeler ce que l'on a fait que d'apprendre théoriquement
  - Utiliser la **saillance** (**emphase** sur parties importantes) y compris à l'oral : forte amélioration de l'apprentissage. Voir : <https://par-temps-clair.blogspot.com/2019/09/saillance-et-attention-en-classe.html>
- Fun fact : la perception du temps change avec l'âge : <https://sdan.io/blog/perceived-age>

### Impact des écrans

- Le _multitasking_ crée de gros soucis de concentration
  - voir expérience : <https://www.radiofrance.fr/franceculture/podcasts/votre-cerveau/multitasking-l-impossible-multitache-des-hyperconnectes-5889944>
- "Flow" : TODO def
  - condition 1 : adéquation entre difficulté de la tâche et récompense

## Organisation

### Inbox 0

- Objectif : Minimiser le temps passé à la gestion des mails
- Principes :
  - Vérifier ses mail à heure fixe et non toute la journée (pas de notification)
  - Catégoriser ses mails dans des répertoires
  - Appliquer un arbre de décision à chaque mail reçu :
    - Faire directement si < 2 min
    - Sinon Différer
    - Déléguer si possible
    - Supprimer si l'e-mail est uniquement informatif
- <http://www.43folders.com/43-folders-series-inbox-zero>
- <https://asana.com/resources/inbox-zero>
- <https://www.microsoft.com/en-us/microsoft-365-life-hacks/organization/inbox-zero-six-tips-for-living-outside-the-box>

### Méthode des J

- Principe : "raffraichir" la mémoire à dates régulières afin d'éviter la courbe de l'oubli en révisant par exemple à :
  - J0, J1, J3, J7, J14, J30
  - J0, J1, J3, J10, J20, J35
  - J0, J2, J5, J14
- En Pratique : QCMs, exercices, … aux dates prévues. L'apprentissage se fait à J0, les autres dates sont de courtes sessions de remémorisation.
- <https://www.adobe.com/fr/acrobat/resources/studying/spaced-repetition-method.html>
- <https://hermione.co/methode-des-j-pass/>

### Prise de notes et rédaction efficaces

- Noter et écrire le fond en _temps réel_
- Avoir une collection d'abbréviations pour gagner du temps
- Séparer d'une colonne : notes objectives "résumé" et notes subjectives "questions / actions à prendre / …"
- Retravailler la forme et la mise en page plus tard
- <https://apprendre5minutes.wordpress.com/2025/03/08/techniques-prise-de-notes-efficaces/>
- <https://kevindetem.com/12-methodes-prise-de-notes-efficace>

### Sketchnote

- Principe : Représenter graphiquement en dessinant et annotant une prise de notes
- Très utile en cours magistral / conférence technique /  … pour résumer un concept complexe
- Voir aussi : <https://www.mindmapping.com/>
- <https://www.insuffle.com/cest-quoi-le-sketchnoting/>
- <https://www.bienenseigner.com/sketchnote/>
- <https://www.optimike.net/sketchnoting/>

### Autres

Voir aussi :

- [Building a Second Brain](/liens#building-a-second-brain)
- [Made to Stick](/liens#made-to-stick)
- <https://email-is-good.com/> : "A site about email productivity."

## Sauvegardes : la règle du 3-2-1-1-0

- 3 = Conservez au moins trois copies de vos données : production, sauvegarde, copie de sauvegarde (en bonus l'archivage compte comme une copie)
- 2 = Utilisez au moins deux types de supports différents pour le stockage (de marque différentes) : disques internes, SAN, NAS (en bonus l'archivage avec les bandes LTO compte comme un support)
- 1 = Conservez au moins une copie hors site : autre site (de production et de sauvegarde) que ce soit une infra de stockage ou dans un coffre-fort par exemple.
- 1 = Conservez au moins une copie hors ligne, isolée ou immuable : c'est surtout pour se prémunir d'une destruction volontaire (ransomware, acte malveillant via accès distant)
- 0 = Zéro erreur après tests de restauration : une sauvegarde non restaurable n'est pas exploitable le jour où on en a besoin.

## Cybersécurité (2020)

- 50% des applications Web ont une faille critique
- 50 nouvelles CVE découvertes chaque jour
- 50% des PME attaquées ont coulé

## IA

### Prompts

#### Générer un bon prompt

- Rôle, contexte, résultat attendu, objectif, contraintes, format
  - _"avant de répondre, pose-moi toutes les questions nécessaires pour optimiser ta réponse"_
  - _"si tu ne sais pas, dis-le moi et n'invente rien"_

- <https://blog.shevarezo.fr/post/2025/12/10/astuces-meilleures-reponses-chatgpt>

#### Types de prompts IA

- _zero-shot_ => pas de contexte
- _few shots_ => contexte par exemples
- _chain of thought_ => "let's think …" (step-by-step example)
- _RAG_ (retrieval augmented generation) => élévation de contexte par vecteur de contexte
- _agents_ => conscience de l'environnement

### Agents

- <https://cursor.com/blog/agent-best-practices>

#### MCP

- MCP best practices from Horacio Gonzalez : [blog](https://lostinbrittany.dev/en/building-smarter-mcp-servers-from-theory-to-practice/) et [slides](https://lostinbrittany.dev/talks/2026/2026-01-16_SnowCamp_MCP-Servers-Good-Practices-Design-Choices-and-Consequences/) :
  - Narrow, named capabilities : each tool should read like a product verb: `getMonsterByName`, `listMonstersByType`, `compareMonsters`.
  - Stable types in/out : explicit schemas (IDs, enums, unions) so the agent can plan reliably.
  - Deterministic behavior : same inputs → same outputs; include `idempotencyKey` when making state changes.
  - Least privilege : tools do one thing; internal queries/side-effects are not exposed.
  - Guardrails at the edge : validate inputs, clamp result sizes, redact PII, enforce authZ inside the server
  - Make the LLM succeed on the first try : types (union, enum), limits, idempotency
  - Always return a **machine part** and a **human part**
- Turn _tasks_ into MCP _tools_/_resources_/_prompts_ :
  - **Tools** (actions) :
    - Read: `getMonsterByName(name) -> Monster`
    - List: `listMonstersByType(type, limit=25, cursor?) -> {items:[Monster], nextCursor}`
    - Search: `searchMonsters(q, limit=10) -> [MonsterSummary]`
  - **Resources** (documents/URIs the client can browse/fetch) :
    - `ragmonsters://schema/Monster` (JSON schema for types)
    - `ragmonsters://docs/query-tips` (compact usage notes)
    - `ragmonsters://images/{monsterId}` (read-only asset stream)
  - **Prompts** (reusable instructions/templates) :
    - `prompt://ragmonsters/answering-style` (tone, do/don't)
    - `prompt://ragmonsters/disambiguation` (ask for missing fields first)

### Utiliser l'IA en formation

Idées d'utilisation de l'IA :

- Générer une réponse par IA, puis l'apprenant fait une critique de la réponse.
- Demander le cheminement : brouillon, suite, …
- Créer un chatbot dédié au cours pour anticiper l'envoi des cours sur chatgpt
- Faire une démo en tant que formateur d'un bon usage de l'IA pour créer le cours
- Moteur d'IA local au campus

Amener la discussion sur l'IA avec les étudiants pour que cela ne soit pas tabou.

#### Règles sur l'utilisation de l'IA générative en cours

Objectif : clarifier les règles IA pour les projets et rendus.

- Sauf mention contraire dans le sujet ou pendant les heures de formation, l'utilisation d'IA est à modérer fortement
  - n'hésitez pas à demander au formateur ce qui est intéressant à faire générer par une IA et ce qui mérite réflexion
  - vous pouvez inclure vos interactions pertinentes (prompts, …) avec les outils d'IA dans le rapport afin d'aider à valider vos compétences
- Vous devez toujours être en capacité d'expliquer 100% de vos rendus, y compris les productions éventuelles d'autres apprenants
- Aucun détecteur d'IA n'est utilisé pour la correction car ceux-ci ne sont pas fiables
  - donc protégez votre proriété intellectuelle et ne soumettez pas vos travaux à ces outils (`zeroGPT`, …) !
- Enfin, vous êtes en mission d'apprentissage : il serait dommage de ne pas profiter de ce temps mis à votre disposition pour monter en compétences

### Les différents types d'apprentissage

- **Apprentissage supervisé** : le modèle apprend à partir de données **étiquetées** (avec réponses connues) pour prédire une sortie lors de nouvelles données.
  - en principe : 80% des données pour l'apprentissage
    - parfois : 20% des données d'apprentissage utilisées en données de **validation** utilisées pour le réglage de l'algorithme pendant l'entraînement, mais pas pour ajuster directement les poids du modèle. Servent à ajuster les **hyperparamètres** : profondeur d'un arbre, taux d'apprentissage d'un réseau de neurones, … ; à décider de l'arrêt de l'entraînement (_early stopping_) ; à comparer plusieurs modèles candidats.
  - 20% pour le test (jamais vues pendant l'entraînement ni pendant la validation, mesurent (impartial) la performance réelle du modèle sur des données nouvelles).
- **Apprentissage non supervisé** : le modèle apprend à partir de données **non étiquetées** et cherche à découvrir (seul) des structures cachées (groupes, similarités, réductions de dimensions).

```
Jeu de données complet
        │
        ├── 70-80 % → Données d'entraînement (train set)
        │              - Utilisées pour ajuster les poids/paramètres du modèle
        │
        ├── 10-15 % → Données de validation (validation set)
        │              - Servent à régler les hyperparamètres
        │              - Aident à éviter le surapprentissage (early stopping)
        │
        └── 10-15 % → Données de test (test set)
                       - Jamais vues avant
                       - Utilisées uniquement pour l'évaluation finale
```

:::link

- Voir aussi : [liens IA](/liens#ia)
- Voir aussi : cours sur [le data mining](/data/mining/cours)

:::

## Adoption

En 2025 (d'après : <https://www.docker.com/blog/2025-docker-state-of-app-dev/>) :

- CI/CD: GitHub Actions (40%), GitLab (39%), Jenkins (36%)
- Provisioning: Terraform (39%), Ansible (35%), GCP (32%)
- Monitoring: Grafana (40%), Prometheus (38%), Elastic (34%)
- Containers in IT : 92%

## Documentation

### Diagramme C4

Type de diagramme très utilisé en agilité, permettant de décrire l'architecture en "zoomant" des composants au code : <https://c4model.com/>

### ADR

Un **ADR** (_Architecture Decision Record_) permet de documenter un choix d'architecture, par exemple avec le formalisme suivant :

> In the context of \<use case/user story>, facing \<concern> we decided for \<option> to achieve \<quality>, accepting \<downside>, because \<additional rationale>.

:::link
Voir aussi : <https://adr.github.io/>
:::

---

## Remerciements

> Merci au <https://snowcamp.io/> pour l'idée du titre de cette section ("hors piste").
